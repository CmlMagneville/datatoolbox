## Quésaco ?

- Extraction via des programmes informatiques (Robots) du contenu de pages Web en vue de son utilisation

- La question de la légalité : le cas Google (le gros foutage de gueule)

--

<br />

- Est-ce que tout peut-être scrapé ?
  - Compte utilisateur
  - Captchas
  - Bannissement d'IP

<br />

--

`r fontawesome::fa_i("hand-point-right", class = "dark")` &nbsp;[**Be polite!**](http://www.user2019.fr/static/pres/lt257430.pdf) with [`{polite}`](https://github.com/dmi3kno/polite/)

--

<br />

Sous `r fontawesome::fa_i("r-project")`, deux approches  :
  1. L'approche brutale (`readLines()` + `regular expressions`)
  1. Le package R : `{rvest}`



---

## Extraction de texte

`r fontawesome::fa_i("hand-point-right", class = "dark")` &nbsp;Source : [**Wikipédia**](https://fr.wikipedia.org/wiki/Liste_des_communes_de_France_les_plus_peuplées)

- Construisons l'URL de la page

```{r echo=TRUE, eval=TRUE}
base_url <- "https://fr.wikipedia.org/wiki/"
article  <- "Acanthurus_lineatus"

request  <- paste0(base_url, article)
```

--

<br />

- Ouverture d'une session HTML

```{r echo=TRUE, eval=TRUE}
html   <- rvest::html_session(request)
```
```{r echo=FALSE, eval=TRUE}
library(magrittr)
```


---

## Extraction de texte

- Extrayons le titre de la page

```{r echo=TRUE, eval=TRUE}
html %>%
  rvest::html_nodes(css = ".firstHeading") %>%
  rvest::html_text()
```


---

## Téléchargement d'une image

- Extrayons l'URL de la troisième image sur la même page

```{r echo=TRUE, eval=TRUE}
img_url <- html %>%
  rvest::html_nodes(xpath = '//*/img') %>%
  rvest::html_attr("src") %>%
  .[3]
```

```
## [1] "//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Acanthurus_lineatus_2...
```

--

<br />

- Téléchargeons l'image

```{r echo=TRUE, eval=FALSE}
download.file(
  url      = paste0("https:", img_url),
  destfile = "acanthurus_lineatus.jpg"
)
```

```
essai de l'URL 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Acanthu...
Content type 'image/jpeg' length 24891 bytes (24 KB)
==================================================
downloaded 24 KB
```



---

## Extraction d'un tableau html

`r fontawesome::fa_i("hand-point-right", class = "dark")` &nbsp;Obtenir le nombre d'habitants des 10 communes les plus peuplées de France (source [**Wikipédia**](https://fr.wikipedia.org/wiki/Liste_des_communes_de_France_les_plus_peuplées))

- Construisons l'URL de la page

```{r echo=TRUE, eval=TRUE}
base_url <- "https://fr.wikipedia.org/wiki/"
article  <- "Liste_des_communes_de_France_les_plus_peuplées"

request  <- paste0(base_url, article)
```

--

<br />

- Ouverture d'une session HTML

```{r echo=TRUE, eval=TRUE}
html   <- rvest::html_session(request)
```



---

## Extraction d'un tableau html

- Extrayons tous les tableaux HTML de la page

```{r echo=TRUE, eval=TRUE}
tables <- rvest::html_table(html, fill = TRUE)
```

--

- Combien en a-t-on ?

```{r echo=TRUE, eval=TRUE}
length(tables)
```

--

- Seul le premier nous intéresse avec les colonnes `Commune` et `2017`

```{r echo=TRUE, eval=TRUE}
cities <- tables[[1]]
cities <- cities[-1, c(3, 7)]
cities <- cities[1:10, ]
rownames(cities) <- NULL
```



---

## Extraction d'un tableau html

- Affichons les données

```{r echo=TRUE, eval=TRUE}
cities
```

<br />

`r fontawesome::fa_i("hand-point-right", class = "dark")` &nbsp;Un peu de nettoyage est nécessaire



---

## Extraction d'un tableau html

- Renommons les colonnes

```{r echo=TRUE, eval=TRUE}
colnames(cities) <- c("city", "pop2017")
```

--

<br />

- Nettoyons le nombre d'habitants

```{r echo=TRUE, eval=TRUE}
cities$pop2017 <- gsub("[[:punct:]]|[[:space:]]", "", cities$pop2017)
cities$pop2017 <- as.numeric(cities$pop2017)
```
```{r echo=FALSE, eval=TRUE}
cities
```



---

## Bonus : Une bubble map


```{r echo=TRUE, eval=TRUE}
api_url   <- "http://nominatim.openstreetmap.org/search/"
params    <- list(format = "json", details = 0, limit = 1)

(locations <- paste0(cities$city, ",%20France"))
```

```{r echo=TRUE, eval=FALSE}
xy <- data.frame()

for (location in locations) {

  request  <- paste0(api_url, location)
  response <- httr::GET(request, query = params)

  datas    <- httr::content(response, as = "text")
  results  <- jsonlite::fromJSON(datas)

  tmp <- results[ , c("lon", "lat")]
  xy  <- rbind(xy, tmp)

  Sys.sleep(1)
}
```

```{r echo=FALSE, eval=TRUE}
xy <- data.frame(
  lon = c(
     2.3514992, 5.3699525, 4.8320114,  1.4442469, 7.2683912,
    -1.5541362, 3.8767337, 7.7507127, -0.5800364, 3.0635282
  ),
  lat = c(
    48.8566101, 43.2961743, 45.7578137, 43.6044622, 43.7009358,
    47.2186371, 43.6112422, 48.5846140, 44.8412250, 50.6365654
  )
)
```



---

## Bonus : Une bubble map

```{r echo=-1, eval=TRUE}
cities[1, 1] <- "Paris"
(xy <- cbind(cities, xy))
```



---
class: middle

.pull-left[
```{r echo=TRUE, eval=FALSE}
## Fond de carte        -----
maps::map(
  region = "France",
  fill   = TRUE,
  col    = "#294557",
  border = "white"
)


## Ajout des points     -----
points(
  x   = xy$lon,
  y   = xy$lat,
  pch = 19,
  col = "#a52a2a88",
  cex = sqrt(cities$pop2017)/(100*pi)
)

## Ajout des villes     -----
text(
  x      = xy$lon,
  y      = xy$lat,
  labels = xy$city,
  col    = "white",
  pos    = 3,
  cex    = 0.75
)
```
]

.pull-right[
.center[
```{r "map2", echo=FALSE, eval=TRUE, dpi=300, fig.path="assets/chunks/", fig.width=3, fig.height=3}
par(bg = "transparent", family = "serif")
maps::map(region = "France", fill = TRUE, col = "#294557", border = "white", lwd = 1, mar = rep(0, 4))
points(xy[ , c("lon", "lat")], pch = 19, col = "#a52a2a", cex = sqrt(cities$pop2017)/(100 *pi))
text(
  x      = xy$lon,
  y      = xy$lat,
  labels = xy$city,
  col    = "white",
  pos    = sample(1:4, nrow(xy), replace = TRUE),
  cex    = 0.75
)
```
]
]
